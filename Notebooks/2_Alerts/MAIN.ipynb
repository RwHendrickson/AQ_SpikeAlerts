{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63c1a05d-d752-41d9-a7d0-8b63dc846daf",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fb6ebb-757c-4a4b-abeb-c86e78e9f72a",
   "metadata": {},
   "source": [
    "## Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaf261ea-6d2f-45a9-9ea2-1812b67f9ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Manipulation\n",
    "\n",
    "import os # For working with Operating System\n",
    "import sys # System arguments\n",
    "from dotenv import load_dotenv # Loading .env info\n",
    "\n",
    "# Web\n",
    "\n",
    "import requests # Accessing the Web\n",
    "\n",
    "# Time\n",
    "\n",
    "import datetime as dt # Working with dates/times\n",
    "import pytz # Timezones\n",
    "import time # For Sleeping\n",
    "\n",
    "# Database \n",
    "\n",
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "\n",
    "# Data Manipulation\n",
    "\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1b4538-6c2f-4ca9-af85-7aab5dbcbf6c",
   "metadata": {},
   "source": [
    "### Load Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3235ee9-e763-4506-aea9-e0d277bfbbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "script_path = os.path.join('..', '..', 'Scripts', 'python')\n",
    "\n",
    "# Function definition - Please see Scripts/python/*\n",
    "exec(open(os.path.join(script_path, 'Get_spikes_df.py')).read())\n",
    "exec(open(os.path.join(script_path, 'Create_messages.py')).read())\n",
    "exec(open(os.path.join(script_path, 'twilio_functions.py')).read())\n",
    "exec(open(os.path.join(script_path, 'Update_Alerts.py')).read())\n",
    "exec(open(os.path.join(script_path, 'Send_Alerts.py')).read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96d00e3-efe2-4cde-b750-863cf229321e",
   "metadata": {},
   "source": [
    "### Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b57d158-0338-4ab6-9f1a-55ddf16fb5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv() # Load .env file\n",
    "\n",
    "## API Keys\n",
    "\n",
    "purpleAir_api = os.getenv('PURPLEAIR_API_TOKEN') # PurpleAir API Read Key\n",
    "\n",
    "redCap_token_signUp = os.getenv('REDCAP_TOKEN_SIGNUP') # Survey Token\n",
    "redCap_token_report = os.getenv('REDCAP_TOKEN_REPORT') # Report Token\n",
    "\n",
    "## Database credentials\n",
    "\n",
    "creds = [os.getenv('DB_NAME'),\n",
    "         os.getenv('DB_USER'),\n",
    "         os.getenv('DB_PASS'),\n",
    "         os.getenv('DB_PORT'),\n",
    "         os.getenv('DB_HOST')\n",
    "        ]\n",
    "\n",
    "pg_connection_dict = dict(zip(['dbname', 'user', 'password', 'port', 'host'], creds))  \n",
    "\n",
    "## Twilio Information\n",
    "\n",
    "TWILIO_ACCOUNT_SID = os.getenv('TWILIO_ACCOUNT_SID')\n",
    "TWILIO_AUTH_TOKEN = os.getenv('TWILIO_AUTH_TOKEN')\n",
    "\n",
    "# Other Constants from System Arguments\n",
    "\n",
    "spike_threshold = 35 # Value which defines an AQ_Spike (Micgrograms per meter cubed)\n",
    "\n",
    "timestep = 10 # Sleep time in between updates (in Minutes)\n",
    "\n",
    "# When to stop the program? (datetime)\n",
    "days_to_run = 7 # How many days will we run this?\n",
    "stoptime = dt.datetime.now() + dt.timedelta(days=days_to_run)\n",
    "\n",
    "# Waking hours\n",
    "too_late_hr = 21 # 9pm\n",
    "too_early_hr = 8 # 8am\n",
    "\n",
    "# Report URL\n",
    "\n",
    "base_report_url = 'https://redcap.ahc.umn.edu/surveys/?s=LN3HHDCJXYCKFCLE'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489020c1-f067-4d71-9284-bac957821529",
   "metadata": {},
   "source": [
    "## While Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea36fd1f-acb3-42d1-977f-87e35b096608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-06 15:47:23.714773\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 155\u001b[0m\n\u001b[1;32m    151\u001b[0m     when_to_awake \u001b[38;5;241m=\u001b[39m now \u001b[38;5;241m+\u001b[39m dt\u001b[38;5;241m.\u001b[39mtimedelta(minutes\u001b[38;5;241m=\u001b[39mtimestep) \n\u001b[1;32m    153\u001b[0m     sleep_seconds \u001b[38;5;241m=\u001b[39m (when_to_awake \u001b[38;5;241m-\u001b[39m dt\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow())\u001b[38;5;241m.\u001b[39mseconds \u001b[38;5;66;03m# - it takes about 3 seconds to run through everything\u001b[39;00m\n\u001b[0;32m--> 155\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43msleep_seconds\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Sleep\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTerminating Program\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### The Script\n",
    "\n",
    "# Initialize storage for reports_for_day\n",
    "\n",
    "reports_for_day = 0\n",
    "\n",
    "while True:\n",
    "\n",
    "    now = dt.datetime.now() # The current time\n",
    "\n",
    "    print(now)\n",
    "\n",
    "    if stoptime < now: # Check if we've hit stoptime\n",
    "        break\n",
    "   \n",
    "   # ~~~~~~~~~~~~~~~~~~~~~\n",
    "   \n",
    "   # if new day: # NOT DONE\n",
    "   #     # Initialize reports_for_day\n",
    "   #     reports_for_day = 0\n",
    "   \n",
    "   # ~~~~~~~~~~~~~~~~~~~~~\n",
    "   \n",
    "   # Query PurpleAir\n",
    "\n",
    "    #  Get the sensor_ids from sensors in our database\n",
    "\n",
    "    sensor_ids = get_sensor_ids(pg_connection_dict) # In Get_Spikes_df.py\n",
    "\n",
    "    # Query PurpleAir for Spikes\n",
    "\n",
    "    spikes_df, runtime, flagged_sensor_ids = Get_spikes_df(purpleAir_api, sensor_ids, spike_threshold) # In Get_Spikes_df.py\n",
    "\n",
    "    # Sort the spiked sensors into new, ongoing, ended spiked sensors, and not spiked sensors\n",
    "\n",
    "    new_spike_sensors, ongoing_spike_sensors, ended_spike_sensors, not_spiked_sensors = sort_sensors_for_updates(spikes_df, sensor_ids, flagged_sensor_ids, pg_connection_dict) # In Update_Alerts.py\n",
    "\n",
    "    # Initialize message/record_id storage\n",
    "    \n",
    "    record_ids_to_text = []\n",
    "    messages = []\n",
    "    \n",
    "    # ~~~~~~~~~~~~~~~~~~~~~\n",
    "    \n",
    "    # NEW Spikes\n",
    "    \n",
    "    if len(new_spike_sensors) > 0:\n",
    "\n",
    "        new_spikes_df = spikes_df[spikes_df.sensor_index.isin(new_spike_sensors)] \n",
    "    \n",
    "        for index, row in new_spikes_df.iterrows():\n",
    "    \n",
    "            # 1) Add to active alerts\n",
    "        \n",
    "            newest_alert_index = add_to_active_alerts(row, pg_connection_dict,\n",
    "                                 runtime.strftime('%Y-%m-%d %H:%M:%S') # When we ran the PurpleAir Query\n",
    "                                ) # In Update_Alerts.py\n",
    "            \n",
    "            # 2) Query users ST_Dwithin 1000 meters & subscribed = TRUE\n",
    "            \n",
    "            record_ids_nearby = Users_nearby_sensor(pg_connection_dict, row.sensor_index, 1000) # in Send_Alerts.py\n",
    "            \n",
    "            if len(record_ids_nearby) > 0:\n",
    "\n",
    "                if (now.hour < too_late_hr) & (now.hour > too_early_hr): # Waking Hours\n",
    "            \n",
    "                    # a) Query users from record_ids_nearby if both active_alerts and cached_alerts are empty\n",
    "                    record_ids_new_alerts = Users_to_message_new_alert(pg_connection_dict, record_ids_nearby) # in Send_Alerts.py & .ipynb \n",
    "                    \n",
    "                    # Compose Messages & concat to messages/record_id_to_text   \n",
    "                    \n",
    "                    # Add to message/record_id storage for future messaging\n",
    "                    record_ids_to_text += record_ids_new_alerts\n",
    "                    messages += [new_alert_message(sensor_id)]*len(record_ids_new_alerts) # in Compose_Messages.py\n",
    "\n",
    "                # b) Add newest_alert_index to record_ids_nearby's Active Alerts\n",
    "    \n",
    "                update_users_active_alerts(record_ids_nearby, newest_alert_index, pg_connection_dict) # in Update_Alerts.py & .ipynb\n",
    "\n",
    "    # ~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "    # ONGOING spikes\n",
    "\n",
    "    if len(ongoing_spike_sensors) > 0:\n",
    "\n",
    "        ongoing_spikes_df = spikes_df[spikes_df.sensor_index.isin(ongoing_spike_sensors)]\n",
    "\n",
    "        for _, spike in ongoing_spikes_df.iterrows():\n",
    "\n",
    "            # 1) Update the maximum reading\n",
    "    \n",
    "            update_max_reading(spike, pg_connection_dict) # In Update_Alerts.py\n",
    "            \n",
    "            # 2) Merge/Cluster alerts? \n",
    "            # NOT DONE - FAR FUTURE TO DO\n",
    "\n",
    "    # ~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "    # ENDED spikes\n",
    "\n",
    "    if len(ended_spike_sensors) > 0:\n",
    "\n",
    "        # 1) Add alert to archive\n",
    "    \n",
    "        add_to_archived_alerts(not_spiked_sensors, pg_connection_dict) # In Update_Alerts.py\n",
    "\n",
    "        # 2) Remove from Active Alerts\n",
    "        \n",
    "        ended_alert_indices = remove_active_alerts(not_spiked_sensors, pg_connection_dict) # # A list from Update_Alerts.py\n",
    "\n",
    "        # 3) Transfer these alerts from \"Sign Up Information\" active_alerts to \"Sign Up Information\" cached_alerts \n",
    "        \n",
    "        cache_alerts(ended_alert_indices, pg_connection_dict) # in Update_Alerts.py & .ipynb\n",
    "\n",
    "        # 4) Query for people to text (subscribed = TRUE and active_alerts is empty and cached_alerts not empty and cached_alerts is > 10 minutes old - ie. ended_alert_indices intersect cached_alerts is empty) \n",
    "        \n",
    "        record_ids_end_alert_message = Users_to_message_end_alert(pg_connection_dict, ended_alert_indices) # in Send_Alerts.py & .ipynb\n",
    "                \n",
    "        # 5) If #4 has elements: for each element (user) in #4\n",
    "        \n",
    "        if len(record_ids_end_alert_message) > 0:\n",
    "        \n",
    "            for record_id in record_ids_end_alert_message:\n",
    "                \n",
    "                # a) Initialize report - generate unique report_id, log cached_alerts and use to find start_time/max reading/duration/sensor_indices\n",
    "                \n",
    "                report_id = str(reports_for_day).zfill(5) + '-' + now.strftime('%m%d%y') # XXXXX-MMDDYY\n",
    "                    \n",
    "                duration_minutes, max_reading = initialize_report(record_id, reports_for_day, pg_connection_dict) # in Send_Alerts.py & .ipynb\n",
    "                \n",
    "                reports_for_day += 1 \n",
    "                \n",
    "                if (now.hour < too_late_hr) & (now.hour > too_early_hr): # Waking hours\n",
    "\n",
    "                    # b) Compose message telling user it's over w/ unique report option & concat to messages/record_ids_to_text\n",
    "                    \n",
    "                    record_ids_to_text += [record_id]\n",
    "                    messages += [end_alert_message(duration_minutes, max_reading, report_id, base_report_url)]\n",
    "\n",
    "                # c) Clear the user's cached_alerts \n",
    "                # - NOT DONE - do in Update_Alerts.py & .ipynb\n",
    "                \n",
    "    # ~~~~~~~~~~~~~~~~~~~~~           \n",
    "    \n",
    "    # Send all messages - NOT DONE do in Send_Alerts.py & .ipynb\n",
    "    \n",
    "    # ~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "    # SLEEP between updates\n",
    "\n",
    "    when_to_awake = now + dt.timedelta(minutes=timestep) \n",
    "\n",
    "    sleep_seconds = (when_to_awake - dt.datetime.now()).seconds # - it takes about 3 seconds to run through everything\n",
    "\n",
    "    time.sleep(sleep_seconds) # Sleep\n",
    "\n",
    "\n",
    "print(\"Terminating Program\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27bc1afc-7a49-41d4-b18d-c82925fd07ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_ids_to_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e93ba34-f04d-4eb9-9480-af2c78f7eacf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Alert Over\\nDuration: 16738 minutes \\nMax value: 79.0 ug/m3\\n\\nReport here - https://redcap.ahc.umn.edu/surveys/?s=LN3HHDCJXYCKFCLE&report_id=00000-110623',\n",
       " 'Alert Over\\nDuration: 1384 minutes \\nMax value: 35.0 ug/m3\\n\\nReport here - https://redcap.ahc.umn.edu/surveys/?s=LN3HHDCJXYCKFCLE&report_id=00001-110623']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
